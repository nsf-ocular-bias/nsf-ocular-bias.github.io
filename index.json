[{"authors":null,"categories":null,"content":"Sreeraj Ramachandran is a Graduate Research Assistant at the Vision Computing and Biometrics Security Lab, Wichita State University. His research include Computer Vision, Biometrics, Bias AI, GANs and adversarial Attacks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/sreeraj-ramachandran/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sreeraj-ramachandran/","section":"authors","summary":"Sreeraj Ramachandran is a Graduate Research Assistant at the Vision Computing and Biometrics Security Lab, Wichita State University. His research include Computer Vision, Biometrics, Bias AI, GANs and adversarial Attacks.","tags":null,"title":"Sreeraj Ramachandran","type":"authors"},{"authors":["Anoop Krishnan"],"categories":null,"content":"Anoop Krishnan is a Ph.D. student at Vision Computing and Biometric Security Lab,Wichita State University. He does research on Fair and Ethical Biometric Systems, which involves studying about the biases in the present systems and mitigate it through deep learning techniques.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da80271efc1c2a67d689eedf34452e4d","permalink":"/author/anoop-krishnan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/anoop-krishnan/","section":"authors","summary":"Anoop Krishnan is a Ph.D. student at Vision Computing and Biometric Security Lab,Wichita State University. He does research on Fair and Ethical Biometric Systems, which involves studying about the biases in the present systems and mitigate it through deep learning techniques.","tags":null,"title":"Anoop Krishnan","type":"authors"},{"authors":["Ajita Rattani"],"categories":null,"content":"Ajita Rattani is an Assistant Professor in the Department of Electrical Engineering and Computer Science at Wichita State University. Prior to this, she was an Adjunct Graduate Faculty at the University of Missouri - Kansas City. She did her Post-doctoral studies from the Department of Computer Science and Engineering, Michigan State University, USA. Ajita obtained her Ph.D. in Computer Science Engineering from the University of Cagliari, Italy.\nHer research interest includes Pattern Recognition, Classifier Fusion, Machine/ Deep Learning, Image Processing, Computer Vision, and Biometrics. She has bagged more than 100 research papers in high impact international conferences and journals. She is the co-editor of the Springer books titled “Adaptive Biometric Systems: Recent Advances and Challenges” and \u0026ldquo;Selfie Biometrics: Advances and Challenges\u0026rdquo;.\nAjita has been the recipient of the Best Paper and Poster awards at IEEE IJCB 2014, IEEE HST 2017 and IAPR Biometric Summer School 2008. She has collaborated with many eminent scientists across the globe in her field of research. She has also spent one year in University of Sassari, Italy (2006-2007) and six months in West Virginia University, USA (2009) as a Visiting Researcher.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6aad9adc76eb3531441fe24660f519b5","permalink":"/author/dr.-ajita-rattani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dr.-ajita-rattani/","section":"authors","summary":"Ajita Rattani is an Assistant Professor in the Department of Electrical Engineering and Computer Science at Wichita State University. Prior to this, she was an Adjunct Graduate Faculty at the University of Missouri - Kansas City.","tags":null,"title":"Dr. Ajita Rattani","type":"authors"},{"authors":[],"categories":null,"content":"Goals and Technical Issues addressed  To address significant advances in the field of fairness and bias in AI with an application to biometrics systems. To provide a common forum for applied and academic researchers to exchange ideas on metrics and methods for evaluating and mitigating demographic effects in biometric performance. To address the disconnect between the work done by government, academicians, and industry.  Topics Covered  Statistical modeling of the demographic bias of the biometric systems across age, gender, and race in different image spectrums. Theoretical explanation and nomenclature regarding demographic effects in biometric systems. Modeling the compound impact of covariates such as lighting variations, make-up, pose, etc., in differential accuracy of the biometric systems across demographic variations. Explainable AI techniques to understand the cause of demographic variations in biometric systems. Evaluation of bias of speaker recognition system, and other behavioral biometrics. Biological origins of demographic effects on physical and behavioral biometric traits. Bias mitigation techniques that offer the best trade-off between accuracy and bias. Bias mitigation techniques in the absence of demographic variables. Techniques on enhancing privacy and fairness of the biometric surveillance system. Evaluation of bias of biometric data manipulation detection algorithms across demographics. Investigation of novel bias-free biometric modalities.  ","date":1661040000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661040000,"objectID":"95c978aaad76ef6b30f8e44deaa67f12","permalink":"/event/umdbb/","publishdate":"2022-01-06T00:00:00Z","relpermalink":"/event/umdbb/","section":"event","summary":"ICPR workshop on bias and fairness of biometric systems.","tags":[],"title":"Understanding and Mitigating Demographic Bias in Biometric Systems(UMDBB)","type":"event"},{"authors":null,"categories":[],"content":"Dataset Gender Classification Results              Subject Verification Results        Subject Verification All Results Table  Visualizations GradCAM GradCAM         Guided GradCAM Guided GradCAM         Occlusion Sensitivity Occlusion Sensitivity         Vanilla Gradients Vanilla Gradients         Integrated Gradients Integrated Gradients         SmoothGrad         -- Gradients x Input Gradients x Input         Averaged Map \u0026times;       References Bibliography called, but no references ","date":1654101352,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654101352,"objectID":"a13db798a5b55a04223e32f31d7512c3","permalink":"/updates/notredame-results/","publishdate":"2022-06-01T11:35:52-05:00","relpermalink":"/updates/notredame-results/","section":"updates","summary":"Dataset Gender Classification Results              Subject Verification Results        Subject Verification All Results Table  Visualizations GradCAM GradCAM         Guided GradCAM Guided GradCAM         Occlusion Sensitivity Occlusion Sensitivity         Vanilla Gradients Vanilla Gradients         Integrated Gradients Integrated Gradients         SmoothGrad         -- Gradients x Input Gradients x Input         Averaged Map \u0026times;       References Bibliography called, but no references ","tags":[],"title":"Notredame Preliminary Results","type":"updates"},{"authors":null,"categories":[],"content":"Dataset   Dataset includes 33,660 ocular samples from 1,122 subjects captured by 196 different mobile.\n  All images were resized to224×224. the complete dataset is classified into three age-groups: namely young (18 to 39), middle-aged (40 to 59), and older adults (60 to 79).\n  User recognition and gender classifier models are fine-tuned on randomly selected gender and age-group balanced subset from 780 participants. Subject-disjoint, gender and age-group-balanced subset selected from 342 subjects are used as the test set for authentication and 260 subjects (130 males and females) for gender classification.\n  Age classifier models are fine-tuned on balanced subset selected from 432 subjects and evaluated on subset from 132 subjects, across 6 age-groups, namely 18−29, 30−39, 40−49, 50−59, 60−69 and 70−79.\n  TABLE I: EER and FNMR at 0.01 and 0.1 FMR for user authentication using CNN models for Left (L), Right (R) ocular region,and their score-level fusion (L+R) for Young, Middle-Aged and Older adults evaluated on balanced version of UFPR ocular datasets.   CNN\n Age-Group\n EER(%)\u0026nbsp;\u0026nbsp; FNMR(%) @ FMR   0.01 0.1   L R L+R L R L+R L R L+R     ResNet-50 Young 8.60 9.52 9.06 37.63 35.35 36.49 53.74 54.03 53.89   Middle-Aged 8.62 9.08 8.85 30.76 25.04 27.9 52.23 48.55 50.39   Older 11.01 11.00 11.01 15.47 19.34 17.405 30.67 30.67 30.67   MobileNet-V2 Young 7.75 7.32 7.54 33.21 26.11 29.66 51.61 48.28 49.95   Middle-Aged 9.08 8.68 8.88 29.18 28.14 28.66 51.17 51.31 51.24   Older 8.04 9.63 8.84 18.54 13.47 16.005 39.47 36.00 37.74   ShuffleNet-V2 Young 6.93 6.96 6.95 37.63 38.09 37.86 56.44 56.26 56.35   Middle-Aged 8.32 9.25 8.79 37.38 46.07 41.73 55.08 61.10 58.09   Older 9.72 8.18 8.95 30.53 30.80 30.67 44.93 53.47 49.20   EfficientNet-B0 Young 7.64 9.61 8.63 32.54 27.00 29.77 55.40 48.38 51.89   Middle-Aged 6.95 9.03 7.99 38.07 26.69 32.38 49.12 49.31 49.22   Older 9.34 12.08 10.71 20.80 23.33 22.065 39.73 41.74 40.74    TABLE II: Accuracy of CNN-based Gender Classification on Left Ocular Region among Young (18 to 39 years), Middle (40 to 59 years) and Older Adults (60 to 79 years).    CNN Young Middle-Aged Older      Male[%] Female[%] Male[%] Female[%] Male[%] Female[%]   ResNet-50 98.39 98.19 100 96.67 99.17 98.06   MobileNet-V2 99.97 99.9 100 99.7 100 100   ShuffleNet-V2-50 98.23 97.57 98.28 97.56 94.76 98.89   EfficientNet-B0 95.89 97.54 98.58 96.44 95.23 86.94    TABLE III: Accuracy of the CNN-based Gender Classification on Right Ocular Region among Young (18 to 39 years), Middle (40 to 59 years) and Older Adults (60 to 79 years).   CNN Young Middle-Aged Older      Male[%] Female[%] Male[%] Female[%] Male[%] Female[%]   ResNet-50 97.98 99.61 97.07 99.78 92.86 98.61   MobileNet-V2 96.84 92.35 95.86 98.66 94.76 97.5   ShuffleNet-V2-50 98.51 98.91 98.79 99.33 97.38 98.61   EfficientNet-B0 97.18 95.14 95.15 97.33 94.52 90    TABLE IV: Exact and 1-off accuracies of Age-group Classification for Young Adults    Left Ocular Right Ocular     CNN Exact [%]  1-off [%] Exact [%]  1-off [%]   ResNet-50 46.72 93 52.87 93.16   MobileNet-V2 54.14 91.78 59.76 94.9   ShuffleNet-V2-50 52.47 91.16 45.16 85.27   EfficientNet-B0 28.225 53.195 31.6 62.64    TABLE V: Exact and 1-off accuracies of Age-group Classification for Middle-Aged Adults.    Left Ocular Right Ocular     CNN Exact [%]  1-off [%] Exact [%]  1-off [%]   ResNet-50 31.61 81.73 35.03 78.43   MobileNet-V2 27.95 86.35 31.86 72.69   ShuffleNet-V2-50 28.46 75.2 24.61 47.98   EfficientNet-B0 20.93 57.86 19.56 55.73    TABLE VI: Exact and 1-off accuracies of Age-group Classification for Older Adults.    Left Ocular Right Ocular     CNN Exact [%]  1-off [%] Exact [%]  1-off [%]   ResNet-50 28 82.3 29.485 71.43   MobileNet-V2 38.07 79.82 32.93 76.65   ShuffleNet-V2-50 36.04 89.65 18.54 56.85   EfficientNet-B0 4.97 32.3 4.74 27    --- References Bibliography called, but no references ","date":1654101352,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654101352,"objectID":"2d5d1b8e3989af34774c16879a04c0e2","permalink":"/updates/ufpr-age/","publishdate":"2022-06-01T11:35:52-05:00","relpermalink":"/updates/ufpr-age/","section":"updates","summary":"Dataset   Dataset includes 33,660 ocular samples from 1,122 subjects captured by 196 different mobile.\n  All images were resized to224×224. the complete dataset is classified into three age-groups: namely young (18 to 39), middle-aged (40 to 59), and older adults (60 to 79).","tags":[],"title":"UFPR Fairness - Across Age","type":"updates"},{"authors":null,"categories":[],"content":"Dataset The UFPR-Periocular dataset was created to obtain images in unconstrained scenarios that contain realistic noises caused by occlusion, blur, and variations in lighting, distance, and angles.\nThe gender distribution of the subjects is $(53,65\\%)$ male and $(46,35\\%)$ female, and approximately $66\\%$ of the subjects are under $31$ years old. In total, the dataset has images captured from $196$ different mobile devices – the five most used device models were: Apple iPhone 8 $(4.1\\%)$, Apple iPhone 9 $(3.1\\%)$, Xiaomi Mi 8 Lite $(3.0\\%)$, Apple iPhone 7 $(3.0\\%)$, and Samsung Galaxy J7 Prime $(2.7\\%)$.\nGender Classification Results              Subject Verification Results        Subject Verification All Results Table  Visualizations GradCAM GradCAM         Guided GradCAM Guided GradCAM         Occlusion Sensitivity Occlusion Sensitivity         Vanilla Gradients Vanilla Gradients         Integrated Gradients Integrated Gradients         SmoothGrad SmoothGrad         Gradients x Input Gradients x Input         Averaged Map \u0026times;       References Bibliography called, but no references ","date":1654101352,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654101352,"objectID":"c155b7f4ec734e028eaee7a3857a0979","permalink":"/updates/ufpr-results/","publishdate":"2022-06-01T11:35:52-05:00","relpermalink":"/updates/ufpr-results/","section":"updates","summary":"Dataset The UFPR-Periocular dataset was created to obtain images in unconstrained scenarios that contain realistic noises caused by occlusion, blur, and variations in lighting, distance, and angles.\nThe gender distribution of the subjects is $(53,65\\%)$ male and $(46,35\\%)$ female, and approximately $66\\%$ of the subjects are under $31$ years old.","tags":[],"title":"UFPR Preliminary Results","type":"updates"},{"authors":["Anoop Krishnan","Ali Almadan","Ajita Rattani"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1634083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634083200,"objectID":"99f1735efaaff9ce390130a4b2a0e8bf","permalink":"/publication/iccst_2021/","publishdate":"2021-10-13T00:00:00Z","relpermalink":"/publication/iccst_2021/","section":"publication","summary":"A number of studies suggest bias of the face biometrics, i.e., face recognition and soft-biometric estimation methods, across gender, race, and age-groups. There is a recent urge to investigate the bias of different biometric modalities toward the deployment of fair and trustworthy biometric solutions. Ocular biometrics has obtained increased attention from academia and industry due to its high accuracy, security, privacy, and ease of use in mobile devices. A recent study in $2020$ also suggested the fairness of ocular-based user recognition across males and females. This paper aims to evaluate the fairness of ocular biometrics in the visible spectrum among age-groups; young, middle, and older adults. Thanks to the availability of the latest large-scale $2020$ UFPR ocular biometric dataset, with subjects acquired in the age range $18$ - $79$ years, to facilitate this study. Experimental results suggest the overall equivalent performance of ocular biometrics across gender and age-groups in user verification and gender-classification. Performance difference for older adults at lower false match rate and young adults was noted at user verification and age-classification, respectively. This could be attributed to inherent characteristics of the biometric data from these age-groups impacting specific applications, which suggest a need for advancement in sensor technology and software solutions.","tags":["Fairness","Bias","Ocular","Analysis"],"title":"Investigating Fairness of Ocular Biometrics Among Young, Middle-Aged, and Older Adults","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]