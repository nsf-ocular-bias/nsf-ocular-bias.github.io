Analyzing and mitigating bias of facial attribute classifiers using ChatGPT:
Ayesha Manzoor, Bharath Krishnamurthy & Ajita Rattani
https://www.sciencedirect.com/science/article/pii/S0925231225014973?ref=pdf_download&fr=RR-2&rr=974de9c9a8cfc871
Recent studies have demonstrated the potential of ChatGPT in facial attribute classification, achieving accuracies comparable to those of vision models. However, limited research has been conducted on the fairness of ChatGPT in this context. This paper investigates the fairness of ChatGPT in facial attribute classification and examines how its natural language explanations (linguistic features) can enhance both fairness and explainability in traditional vision model for facial attribute classification by proposing: (a) a novel training framework that integrates ChatGPT’s linguistic features with vision models to improve both classification accuracy and fairness, and (b) a mapping function between the feature spaces of vision and language models, enabling ChatGPT to provide natural language explanations of the vision model’s decision-making process. To evaluate our approach, we conduct two types of experiments: (1) face-based gender classification, where race is considered the protected attribute, and (2) gender-independent classification of 13 facial attributes, where gender is the protected attribute. Our experimental results on popular facial attribute datasets show that ChatGPT offers complementary strengths in obtaining fairer outcomes over vision classifiers for different facial attribute classification tasks across demographic attributes. Moreover, incorporating ChatGPT’s linguistic descriptions enhances vision model accuracy by 1.16% to 1.34%, reduces demographic performance disparities by 1.23% to 11.32%, and provides interpretable explanations, all without altering the architecture of the vision model.
2025

FineFACE: Fair Facial Attribute Classification Leveraging Fine-Grained Features
Ayesha Manzoor & Ajita Rattani
https://link.springer.com/chapter/10.1007/978-3-031-78110-0_6
Published research highlights the presence of demographic bias in automated facial attribute classification algorithms, particularly impacting women and individuals with darker skin tones. Existing bias mitigation techniques typically require demographic annotations and often obtain a trade-off between fairness and accuracy, i.e., Pareto inefficiency. Facial attributes, whether common ones like gender or others such as "chubby" or "high cheekbones", exhibit high interclass similarity and intraclass variation across demographics leading to unequal accuracy. This necessitates the use of local and subtle cues using fine-grained analysis for differentiation. This paper proposes a novel approach to fair facial attribute classification by framing it as a fine-grained classification problem. Our approach effectively integrates both low-level local features (like edges and color) and high-level semantic features (like shapes and structures) through cross-layer mutual attention learning. Here, shallow to deep CNN layers function as experts, offering category predictions and attention regions.
02 December 2024

Benchmarking Neural Network Compression Techniques for Ocular-Based User Authentication on Smartphones
Ali Almadan & Ajita Rattani
https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9esyU2EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=9esyU2EAAAAJ:BUYA1_V_uYcC
With the unprecedented mobile technology revolution, mobile devices have transcended from being the primary means of communication to an all-in-one platform. Consequently, an increasing number of individuals are accessing online services for e-commerce and banking via smartphones instead of traditional desktop computers. However, smartphones can be easily misplaced, lost, or stolen more often than other computing devices, thereby demanding effective user authentication mechanisms for device unlocking and secured transactions. Ocular biometrics has obtained significant attention from academia and industry because of its accuracy, security, and ease of use in mobile devices. Several studies have demonstrated the efficacy of deep learning models for ocular-based user authentication on smartphones. However, these high-performing models require enormous space and computational complexity due to the millions of parameters and computations involved. These requirements make their deployment on resource-constrained smartphones challenging. To this end, a handful of studies have been proposed for compact-size ocular-based deep-learning models to facilitate on-device deployment. In this paper, we conduct a thorough analysis of the existing neural network compression techniques applied as a standalone and in combination for ocular-based user authentication. Extensive experimental validation is performed on the two latest large-scale ocular biometric datasets collected using smartphones, namely, UFPR and VISOB 2.0 datasets. This study benchmarks the results of advanced compression techniques for further research and development in lightweight models for ocular-based user authentication on smartphones.
06 April 2023

A Self-Supervised Learning Pipeline for Demographically Fair Facial Attribute Classification
Sreeraj Ramachandran & Ajita Rattani
https://ieeexplore.ieee.org/abstract/document/10744477
Published research highlights the presence of demographic bias in automated facial attribute classification. The proposed bias mitigation techniques are mostly based on supervised learning, which requires a large amount of labeled training data for generalizability and scalability. However, labeled data is limited, requires laborious annotation, poses privacy risks, and can perpetuate human bias. In contrast, self-supervised learning (SSL) capitalizes on freely available unlabeled data, rendering trained models more scalable and generalizable. However, these label-free SSL models may also introduce biases by sampling false negative pairs, especially at low-data regimes (< 200K images) under low compute settings. Further, SSL-based models may suffer from performance degradation due to a lack of quality assurance of the unlabeled data sourced from the web. This paper proposes a fully self-supervised pipeline for demographically fair facial attribute classifiers. Leveraging completely unlabeled data pseudolabeled via pre-trained encoders, diverse data curation techniques, and meta-learning-based weighted contrastive learning, our method significantly outperforms existing SSL approaches proposed for downstream image classification tasks. Extensive evaluations on the FairFace and CelebA datasets demonstrate the efficacy of our pipeline in obtaining fair performance over existing baselines. Thus, setting a new benchmark for SSL in the fairness of facial attribute classification. To facilitate reproducibility, the code, and the curated dataset information is available at https://github.com/nsf-ocular-bias/ssl-ijcb.
11 November 2024

A novel approach for bias mitigation of gender classification algorithms using consistency regularization
Anoop Krishnan & Ajita Rattani
https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9esyU2EAAAAJ&pagesize=80&sortby=pubdate&citation_for_view=9esyU2EAAAAJ:vbGhcppDl1QC
Published research has confirmed the bias of automated face-based gender classification algorithms across gender-racial groups. Specifically, unequal accuracy rates were obtained for women and dark-skinned people for face-based automated gender classification algorithms. To mitigate the bias of gender classification and other facial-analysis-based algorithms in general, the vision community has proposed several techniques. However, most of the existing bias mitigation techniques suffer from a lack of generalizability, need a demographically-annotated training set, are application-specific, and often offer a trade-off between fairness and classification accuracy. This means that fairness is often obtained at the cost of a reduction in the classification accuracy of the best-performing demographic sub-group. In this paper, we propose a novel bias mitigation technique that leverages the power of semantic preserving augmentations at the image- and feature-level in a self-consistency setting for the downstream gender classification task. Thorough experimental validation on gender-annotated facial image datasets confirms the efficacy of our bias mitigation technique in improving overall gender classification accuracy as well as reducing bias across all gender-racial groups over state-of-the-art bias mitigation techniques.
September 2023